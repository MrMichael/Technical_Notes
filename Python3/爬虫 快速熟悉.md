# 爬虫快速熟悉



## 介绍

### 1.概念

爬虫：一段自动抓取互联网信息的程序，从互联网上抓取对于我们有价值的信息。



### 2.Python爬虫架构

![](https://img-blog.csdn.net/20170826134318809?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXE0MDczODgzNTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

Python 爬虫架构主要由五个部分组成：

- **调度器：**是程序入口，负责调度URL管理器、下载器、解析器之间的协调工作。

- **URL管理器：**负责管理爬取页面的URL地址管理，包括待爬取的URL地址和已爬取的URL地址，防止重复抓取URL和循环抓取URL。实现URL管理器主要用三种方式：

  - 内存：爬取的URL的数量不大时，可直接存在Python内存中，如set()，也省掉去重工作。
  - 数据库：如MySQL等，设置url和is_crawled字段，存储和判断是否已爬取。
  - 缓存数据库：redis，基于内存亦可持久化的日志型、Key-Value数据库。

- **网页下载器：**将URL网页转换成一个字符串并下载到本地。网页下载器有：

  - urllib2（Python官方基础模块）包括需要登录、代理、和cookie。
  - requests(第三方包)

- **网页解析器：**将一个网页字符串进行解析。解析器类型：

  - 模糊匹配：正则表达式

  - 结构化解析：将下载的整个HTML文档当成一个Doucment对象【DOM树结构】，然后在利用其上下结构的标签形式，对这个对象进行上下级的标签进行遍历和信息提取操作。工具有

    - html.parser（Python自带的）
    - beautifulsoup（第三方插件，可以使用Python自带的html.parser进行解析，也可以使用lxml进行解析，相对于其他几种来说要强大一些）
    - lxml（第三方插件，可以解析 xml 和 HTML）

    DOM树解释：即文档对象模型（Document Object Model）。

    ![](https://upload-images.jianshu.io/upload_images/6201367-954d43c50c3f6a37.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/894/format/webp)

- **应用程序：**就是从网页中提取的有用数据组成的一个应用。



### 3.动态网页与静态网页

- 静态网页：随着html代码的生成，页面的内容和显示效果就基本上不会发生变化了——除非你修改页面代码。

- 动态网页：页面代码虽然没有变，但是显示的内容却是可以随着时间、环境或者数据库操作的结果而发生改变的。

注意：动态网页，与网页上的各种动画、滚动字幕等视觉上的动态效果没有直接关系，动态网页也可以是纯文字内容的，也可以是包含各种动画的内容，这些只是网页具体内容的表现形式。无论网页是否具有动态效果，只要是采用了动态网站技术生成的网页都可以称为动态网页。



## 环境搭建

基于ubuntu 18.04 64位系统



### 1.安装BeautifulSoup

For **python2.x**:

```shell
sudo pip install BeautifulSoup4
```

For **python3**:

```shell
sudo apt-get install python3-bs4
```

验证BeautifulSoup

- 进入Python直接import一下，如果没有异常，那就说明安装成功

```shell
$ python3
Python 3.6.7 (default, Oct 22 2018, 11:32:17)
[GCC 8.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from bs4 import BeautifulSoup
>>>
```



### 2.安装selenium

Selenium 库是一个在WebDriver 上调用的API。WebDriver也可以像BeautifulSoup对象一样用来查找页面元素，与页面上的元素进行交互（发送文本、点击等），以及执行其他动作来运行网络爬虫。

```shell
sudo apt install python-selenium # for Python 2.x
```

and/or

```shell
sudo apt install python3-selenium # for Python 3.x  
```

验证

```shell

$ python3
Python 3.6.7 (default, Oct 22 2018, 11:32:17)
[GCC 8.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from selenium import webdriver
>>>
```



### 3.安装Phantomjs

安装依赖文件

```shell
sudo apt-get install build-essential chrpath libssl-dev libxft-dev libfreetype6-dev libfreetype6 libfontconfig1-dev libfontconfig1 -y
```

下载Phantomjs(2.1.1版本)

- 32位：wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-i686.tar.bz2
- 64位：wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2

解压文件：

- 32 位：tar -xvf [phantomjs-2.1.1-linux-i686.tar.bz2](https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-i686.tar.bz2)

- 64位：tar -xvf [phantomjs-2.1.1-linux-x86_64.tar.bz2](https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2)

设置环境变量：

- sudo vi /etc/profile 在末尾解压路径下的bin文件路劲添加：
  - export PATH=$PATH:/home/michael/crawler/phantomjs-2.1.1-linux-x86_64/bin 

验证：

```shell
$ phantomjs --version
2.1.1
```





















